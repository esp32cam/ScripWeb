{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gspread google-auth google-auth-oauthlib google-auth-httplib2\n",
    "# ! pip install --upgrade certifi\n",
    "# ! pip install mysql-connector-python\n",
    "# ! pip install google-auth\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import mysql.connector\n",
    "import yfinance as yf\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from functools import lru_cache\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'tahoma'\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "#import gspread_dataframe as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def get_data():\n",
    "    # โหลดข้อมูลรับรอง JSON จากไฟล์ที่คุณดาวน์โหลด\n",
    "    credentials = Credentials.from_service_account_file('keys.json', scopes=['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive'])\n",
    "\n",
    "    # ตั้งค่าการเชื่อมต่อ gspread ด้วยข้อมูลรับรอง\n",
    "    gc = gspread.service_account(filename='keys.json')\n",
    "\n",
    "    # เปิดสเปรดชีตของ Google Sheets โดยใช้ชื่อหรือ URL\n",
    "    spreadsheet = gc.open('stores_shopee')\n",
    " \n",
    "    # เลือกชีตที่ต้องการใน Google Sheets\n",
    "    worksheet = spreadsheet.worksheet('ชีต1')\n",
    "\n",
    "    # อ่านข้อมูลจากชีตเป็นรายการของดิกชันนารี\n",
    "    data = worksheet.get_all_records()\n",
    "\n",
    "    # สร้าง DataFrame จากข้อมูล\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Brand Link</th>\n",
       "      <th>Vm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acnoc Thailand_Official</td>\n",
       "      <td>https://shopee.co.th/acnoc_thailand</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alcon</td>\n",
       "      <td>https://shopee.co.th/alcon_thailand_official</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ample N</td>\n",
       "      <td>https://shopee.co.th/amplen_official_thailand</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apivita</td>\n",
       "      <td>https://shopee.co.th/apivita_officialshop</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arty</td>\n",
       "      <td>https://shopee.co.th/bsc_official_store</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>somjai_canvas</td>\n",
       "      <td>https://shopee.co.th/somjai_canvas</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>ศึกษาภัณฑ์พาณิชย์</td>\n",
       "      <td>https://shopee.co.th/suksapanmall</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>TKSPAPER_OFFICIAL</td>\n",
       "      <td>https://shopee.co.th/tkspaper_official</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Vusign</td>\n",
       "      <td>https://shopee.co.th/vusign</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>639 Packing</td>\n",
       "      <td>https://shopee.co.th/639express_officialshop</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand Name                                     Brand Link  \\\n",
       "0    Acnoc Thailand_Official            https://shopee.co.th/acnoc_thailand   \n",
       "1                      Alcon   https://shopee.co.th/alcon_thailand_official   \n",
       "2                    Ample N  https://shopee.co.th/amplen_official_thailand   \n",
       "3                    Apivita      https://shopee.co.th/apivita_officialshop   \n",
       "4                       arty        https://shopee.co.th/bsc_official_store   \n",
       "..                       ...                                            ...   \n",
       "711            somjai_canvas             https://shopee.co.th/somjai_canvas   \n",
       "712        ศึกษาภัณฑ์พาณิชย์              https://shopee.co.th/suksapanmall   \n",
       "713        TKSPAPER_OFFICIAL         https://shopee.co.th/tkspaper_official   \n",
       "714                   Vusign                    https://shopee.co.th/vusign   \n",
       "715              639 Packing   https://shopee.co.th/639express_officialshop   \n",
       "\n",
       "     Vm  \n",
       "0     4  \n",
       "1     4  \n",
       "2     4  \n",
       "3     4  \n",
       "4     4  \n",
       "..   ..  \n",
       "711   4  \n",
       "712   4  \n",
       "713   4  \n",
       "714   4  \n",
       "715   4  \n",
       "\n",
       "[716 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# กำหนด vm และสร้าง df ใหม่\n",
    "vm = 4\n",
    "\n",
    "df = df[df['Vm'] == vm]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df['Brand Name'] == 'dearest_official'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df_check:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf_check\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n",
      "File \u001b[1;32mc:\\Users\\arzo4\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\arzo4\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\arzo4\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "for i in df_check:\n",
    "    if df_check[i] == True:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import pandas as pd\n",
    "import undetected_chromedriver as uc\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import zip_longest\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# อ่านไฟล์ชื่อร้านทั้งหมด\n",
    "brand_URL = pd.read_csv('shopee_brand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load proxies from valid_proxies.txt\n",
    "with open(\"proxyscrape_premium_http_proxies.txt\", \"r\") as file:\n",
    "    proxies = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using proxy: 154.6.97.163:3128\n",
      "acnoc_thailand\n",
      "Using proxy: 38.62.221.67:3128\n",
      "Element not found.\n",
      "acnoc_thailand มีสินค้า 10\n",
      "alcon_thailand_official\n",
      "alcon_thailand_official มีสินค้า 12\n",
      "amplen_official_thailand\n",
      "amplen_official_thailand มีสินค้า 36\n",
      "apivita_officialshop\n",
      "apivita_officialshop มีสินค้า 12\n",
      "bsc_official_store\n",
      "bsc_official_store มีสินค้า 383\n",
      "babybright_official\n",
      "babybright_official มีสินค้า 67\n",
      "barbieswink.official\n",
      "barbieswink.official มีสินค้า 18\n",
      "beauticool_officialshop\n",
      "beauticool_officialshop มีสินค้า 385\n",
      "beautyscents\n",
      "beautyscents มีสินค้า 51\n",
      "better_period\n",
      "better_period มีสินค้า 8\n",
      "wiprounza_bioessence\n",
      "wiprounza_bioessence มีสินค้า 22\n",
      "biowoman\n",
      "biowoman มีสินค้า 92\n",
      "bodyearth_direct\n",
      "bodyearth_direct มีสินค้า 9\n",
      "bootsthailand\n",
      "bootsthailand มีสินค้า 570\n",
      "brushme_toothbrush\n",
      "brushme_toothbrush มีสินค้า 14\n",
      "camella_cosmetic\n",
      "camella_cosmetic มีสินค้า 9\n",
      "cathydollofficial\n",
      "cathydollofficial มีสินค้า 130\n",
      "certaindri_official\n",
      "certaindri_official มีสินค้า 8\n",
      "charmiss_cosmetics\n",
      "charmiss_cosmetics มีสินค้า 28\n",
      "chuo_official\n",
      "chuo_official มีสินค้า 20\n",
      "cocorotokyo_official\n",
      "cocorotokyo_official มีสินค้า 43\n",
      "cos_coseutics_and_deodomin\n",
      "cos_coseutics_and_deodomin มีสินค้า 20\n",
      "curamd\n",
      "curamd มีสินค้า 13\n",
      "dnetwork_officialshop\n",
      "dnetwork_officialshop มีสินค้า 19\n",
      "dashingdiva\n",
      "dashingdiva มีสินค้า 109\n",
      "cpconsumer_official\n",
      "cpconsumer_official มีสินค้า 42\n",
      "dearest_official\n",
      "Using proxy: 154.6.96.18:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.17:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.244:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.222.219:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.99.198:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.220.118:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.249:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.220.114:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.197:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.220.63:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.99.138:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.215:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.220.4:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.37:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.220.22:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.98.245:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.222.122:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.96.211:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.221.69:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.249:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.221.153:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.118:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.75:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.220.195:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.221.126:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.98.239:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.98.199:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.220.47:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.207:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.44:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.160:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.148:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.66:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.143:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.96.14:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.161:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.159:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.220.249:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.222.205:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.222.124:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.96.177:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.171:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.221.78:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.98.183:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.113:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.96.130:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.96.213:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.99.24:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.99.4:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.96.108:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.222.170:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.222.37:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.221.174:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.99.6:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.65:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.221.253:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.98.20:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.220.239:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.96.5:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.251:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.237:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.3:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.99.215:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.115:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.15:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.223.172:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.97.248:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.221.230:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.99.71:3128\n",
      "Element not found.\n",
      "Using proxy: 38.62.222.191:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.96.56:3128\n",
      "Element not found.\n",
      "Using proxy: 154.6.98.25:3128\n",
      "Element not found.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 123\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     element_pagemax \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxpath_pagemax\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    124\u001b[0m     element_pagemax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(element_pagemax)\n",
      "File \u001b[1;32mc:\\Users\\arzo4\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:742\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    740\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\arzo4\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:348\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\arzo4\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/fieldset/div[3]/div/span[2]\"}\n  (Session info: chrome=120.0.6099.111); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6046D2142+3514994]\n\t(No symbol) [0x00007FF6042F0CE2]\n\t(No symbol) [0x00007FF6041976AA]\n\t(No symbol) [0x00007FF6041E1860]\n\t(No symbol) [0x00007FF6041E197C]\n\t(No symbol) [0x00007FF604224EE7]\n\t(No symbol) [0x00007FF60420602F]\n\t(No symbol) [0x00007FF6042228F6]\n\t(No symbol) [0x00007FF604205D93]\n\t(No symbol) [0x00007FF6041D4BDC]\n\t(No symbol) [0x00007FF6041D5C64]\n\tGetHandleVerifier [0x00007FF6046FE16B+3695259]\n\tGetHandleVerifier [0x00007FF604756737+4057191]\n\tGetHandleVerifier [0x00007FF60474E4E3+4023827]\n\tGetHandleVerifier [0x00007FF6044204F9+689705]\n\t(No symbol) [0x00007FF6042FC048]\n\t(No symbol) [0x00007FF6042F8044]\n\t(No symbol) [0x00007FF6042F81C9]\n\t(No symbol) [0x00007FF6042E88C4]\n\tBaseThreadInitThunk [0x00007FFBD263257D+29]\n\tRtlUserThreadStart [0x00007FFBD312AA58+40]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 128\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NoSuchElementException:\n\u001b[0;32m    127\u001b[0m     proxy_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 128\u001b[0m     current_proxy \u001b[38;5;241m=\u001b[39m \u001b[43mproxies\u001b[49m\u001b[43m[\u001b[49m\u001b[43mproxy_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing proxy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_proxy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# Add proxy to Chrome options\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from calendar import c\n",
    "from telnetlib import NOP\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from zmq import proxy\n",
    "\n",
    "pd.options.display.float_format = \"{:,.0f}\".format\n",
    "\n",
    "data_df = pd.DataFrame(columns=['ชื่อสินค้า','ราคา','จำนวนขาย','ชื่อร้านค้า'])\n",
    "options = webdriver.ChromeOptions()\n",
    "options.headless = False  # Set to False if you want to see the browser\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "driver.execute_script(\"window.open('','_blank');\")\n",
    "\n",
    "driver.get('https://shopee.co.th/buyer/login?')\n",
    "\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "time.sleep(3)\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//*[@id=\"modal\"]/div[1]/div[1]/div/div[3]/div[1]/button'))\n",
    ")\n",
    "\n",
    "# ค้นหา element ด้วย XPath และคลิก\n",
    "button = driver.find_element(By.XPATH, '//*[@id=\"modal\"]/div[1]/div[1]/div/div[3]/div[1]/button')\n",
    "button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# รอ element ที่ต้องการให้ปรากฎ\n",
    "input_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[2]/form/div[1]/div[1]/input'))\n",
    ")\n",
    "\n",
    "# เติมข้อมูลลงใน input\n",
    "input_element.send_keys(\"quantideatrade410@gmail.com\")\n",
    "\n",
    "input_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[2]/form/div[2]/div[1]/input'))\n",
    ")\n",
    "\n",
    "# เติมข้อมูลลงใน input\n",
    "input_element.send_keys(\"Pongsapak1341?\")\n",
    "time.sleep(5)\n",
    "\n",
    "# อื่น ๆ ที่คุณต้องการทำต่อไป\n",
    "\n",
    "button_login = driver.find_element(By.XPATH, '//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[2]/form/button')\n",
    "button_login.click()\n",
    "time.sleep(5)\n",
    "driver.switch_to.window(driver.window_handles[1])\n",
    "driver.close()\n",
    "\n",
    "\n",
    "# Initialize proxy index\n",
    "proxy_index = 0\n",
    "firsttime = 1\n",
    "\n",
    "#ลูปว่างานเสร็จหรือยัง\n",
    "while True:\n",
    "    \n",
    "    while proxy_index < len(proxies):\n",
    "        # Set the current proxy\n",
    "        current_proxy = proxies[proxy_index]\n",
    "        print(f\"Using proxy: {current_proxy}\")\n",
    "\n",
    "        # Add proxy to Chrome options\n",
    "        options.add_argument(f'--proxy-server=http://{current_proxy}')\n",
    "\n",
    "        # Create a new driver with the current proxy\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "        #ลูปดึงข้อมูลจาก DataFrame\n",
    "        for index, row in df[df['Vm'] == vm].iterrows():\n",
    "            count_store =+1\n",
    "            brand_link = row['Brand Link']\n",
    "            # Split the URL by '/' and get the last part\n",
    "            store_name = brand_link.split('/')[-1]\n",
    "            print(store_name)\n",
    "            \n",
    "            # captcha ครั้งแรก\n",
    "            if firsttime == 1:\n",
    "                driver.get(brand_link + '?page=0')\n",
    "                time.sleep(20)\n",
    "                firsttime = 0\n",
    "                driver.get(brand_link + '?page=0')\n",
    "                \n",
    "\n",
    "            else:   \n",
    "                try:\n",
    "                    # Close the current WebDriver session\n",
    "                    driver.quit()\n",
    "\n",
    "                    # Create a new instance of the WebDriver\n",
    "                    driver = webdriver.Chrome(options=options)\n",
    "                    \n",
    "                    # เปิดเว็บไซต์ที่ต้องการในแท็บปัจจุบัน\n",
    "                    driver.get(brand_link + '?page=0')\n",
    "\n",
    "                    time.sleep(5)\n",
    "                    \n",
    "                except (TimeoutException, ConnectionRefusedError, StaleElementReferenceException, NoSuchElementException) as e:\n",
    "                    \n",
    "                    print(f\"Error: {e}.\")\n",
    "                    print('โหลดหน้าไม่ได้')\n",
    "                \n",
    "            # xpath to text page number loop\n",
    "            xpath_pagemax = '//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/fieldset/div[3]/div/span[2]'\n",
    "            element_pagemax = None\n",
    "            \n",
    "            s = 0\n",
    "            # ลูปหาจำนวนหน้า\n",
    "            while element_pagemax is None:\n",
    "                if element_pagemax is not None:\n",
    "                    break\n",
    "                \n",
    "                elif s == 4:\n",
    "                    element_pagemax = 0  \n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    element_pagemax = driver.find_element(By.XPATH, xpath_pagemax).text\n",
    "                    element_pagemax = int(element_pagemax)\n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    proxy_index += 1\n",
    "                    current_proxy = proxies[proxy_index]\n",
    "                    print(f\"Using proxy: {current_proxy}\")\n",
    "                    # Add proxy to Chrome options\n",
    "                    options.add_argument(f'--proxy-server=http://{current_proxy}')\n",
    "\n",
    "                    # Create a new driver with the current proxy\n",
    "                    driver = webdriver.Chrome(options=options)\n",
    "                    driver.get(brand_link + '?page=0')\n",
    "\n",
    "                    print(\"Element not found.\")\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                s =+ 1\n",
    "                \n",
    "            store_item = 0\n",
    "            try:\n",
    "                page = df['Brand Link'] \n",
    "                page_print = page.split('=')[1]\n",
    "            \n",
    "            except (IndexError, AttributeError) :\n",
    "                page_print = 99999\n",
    "            \n",
    "            # เป็นหน้าจริงๆ \n",
    "            if page_print < 3:\n",
    "                current_page = int(page_print)\n",
    "                \n",
    "            if page_print > 3:\n",
    "                current_page = 99999\n",
    "            \n",
    "            # ลูปชั้น 1\n",
    "            if element_pagemax <= 20:\n",
    "                \n",
    "                try:\n",
    "                    for item in range(1, 31):  # Loop through items\n",
    "                            try:\n",
    "                                \n",
    "                                xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[1]/div/div'\n",
    "                                element = driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "                                # Extract and process data as needed\n",
    "                                data = element.text\n",
    "\n",
    "                                # Find the price element for the current item\n",
    "                                price_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                                price_element = driver.find_element(By.XPATH, price_xpath)\n",
    "\n",
    "                                # Extract and process price data\n",
    "                                price_data = price_element.text\n",
    "\n",
    "                                sales_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[1]/div[1]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                                sales_element = driver.find_element(By.XPATH, sales_xpath)\n",
    "                                sales_data = sales_element.text\n",
    "\n",
    "                                # Create a new DataFrame with the extracted data\n",
    "                                new_data = pd.DataFrame({'ชื่อสินค้า': [data], 'ราคา': [price_data],'จำนวนขาย':[sales_data],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                                # Concatenate the new DataFrame with the existing data_df\n",
    "                                data_df = pd.concat([data_df, new_data], ignore_index=True)\n",
    "\n",
    "                                store_item += 1\n",
    "                                \n",
    "                            except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                                continue\n",
    "\n",
    "\n",
    "                    for list_number in range(1, element_pagemax):\n",
    "                        url = f'https://shopee.co.th/{store_name}?page={str(list_number)}'\n",
    "\n",
    "                        \n",
    "                        driver.get(url)\n",
    "                        time.sleep(5)\n",
    "                        \n",
    "                        for item in range(1, 31):  # Loop through items\n",
    "                            try:\n",
    "                                \n",
    "                                xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[1]/div/div'\n",
    "                                element = driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "                                # Extract and process data as needed\n",
    "                                data = element.text\n",
    "\n",
    "                                # Find the price element for the current item\n",
    "                                price_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                                price_element = driver.find_element(By.XPATH, price_xpath)\n",
    "\n",
    "                                # Extract and process price data\n",
    "                                price_data = price_element.text\n",
    "\n",
    "                                sales_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[1]/div[1]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                                sales_element = driver.find_element(By.XPATH, sales_xpath)\n",
    "                                sales_data = sales_element.text\n",
    "\n",
    "                                # Create a new DataFrame with the extracted data\n",
    "                                new_data = pd.DataFrame({'ชื่อสินค้า': [data], 'ราคา': [price_data],'จำนวนขาย':[sales_data],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                                # Concatenate the new DataFrame with the existing data_df\n",
    "                                data_df = pd.concat([data_df, new_data], ignore_index=True)\n",
    "                                \n",
    "\n",
    "                                store_item += 1\n",
    "    \n",
    "                            except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                                continue  \n",
    "                                \n",
    "                        for item in range(1, 31):  # Loop through items \n",
    "                            try:\n",
    "                            \n",
    "                                xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div'\n",
    "                                element2 = driver.find_element(By.XPATH, xpath2)\n",
    "\n",
    "                                # Extract and process data as needed\n",
    "                                data2 = element2.text\n",
    "\n",
    "                                # Find the price element for the current item\n",
    "                                price_xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                                price_element2 = driver.find_element(By.XPATH, price_xpath2)\n",
    "\n",
    "                                # Extract and process price data\n",
    "                                price_data2 = price_element2.text\n",
    "\n",
    "                                sales_xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                                sales_element2 = driver.find_element(By.XPATH, sales_xpath2)\n",
    "                                sales_data2 = sales_element2.text\n",
    "\n",
    "                                # Create a new DataFrame with the extracted data\n",
    "                                new_data2 = pd.DataFrame({'ชื่อสินค้า': [data2], 'ราคา': [price_data2],'จำนวนขาย':[sales_data2],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                                # Concatenate the new DataFrame with the existing data_df\n",
    "                                data_df = pd.concat([data_df, new_data2], ignore_index=True)  \n",
    "                                \n",
    "                                \n",
    "                            except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                                continue  \n",
    "            \n",
    "                except:\n",
    "                    print(\"Next page not found.\")\n",
    "                    \n",
    "                print(f'{store_name} มีสินค้า {store_item}')    \n",
    "            # ถึงหน้าสุดท้ายแล้ว\n",
    "            elif element_pagemax == current_page:\n",
    "                \n",
    "                for item in range(1, 31):  # Loop through items\n",
    "                    try:\n",
    "                        \n",
    "                        xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[1]/div/div'\n",
    "                        element = driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "                        # Extract and process data as needed\n",
    "                        data = element.text\n",
    "\n",
    "                        # Find the price element for the current item\n",
    "                        price_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                        price_element = driver.find_element(By.XPATH, price_xpath)\n",
    "\n",
    "                        # Extract and process price data\n",
    "                        price_data = price_element.text\n",
    "\n",
    "                        sales_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[1]/div[1]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                        sales_element = driver.find_element(By.XPATH, sales_xpath)\n",
    "                        sales_data = sales_element.text\n",
    "\n",
    "                        # Create a new DataFrame with the extracted data\n",
    "                        new_data = pd.DataFrame({'ชื่อสินค้า': [data], 'ราคา': [price_data],'จำนวนขาย':[sales_data],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                        # Concatenate the new DataFrame with the existing data_df\n",
    "                        data_df = pd.concat([data_df, new_data], ignore_index=True)\n",
    "\n",
    "                        store_item += 1\n",
    "                    except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                        continue  \n",
    "                        \n",
    "                for item in range(1, 31):  # Loop through items\n",
    "                    try:\n",
    "                    \n",
    "                        xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div'\n",
    "                        element2 = driver.find_element(By.XPATH, xpath2)\n",
    "\n",
    "                        # Extract and process data as needed\n",
    "                        data2 = element2.text\n",
    "\n",
    "                        # Find the price element for the current item\n",
    "                        price_xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                        price_element2 = driver.find_element(By.XPATH, price_xpath2)\n",
    "\n",
    "                        # Extract and process price data\n",
    "                        price_data2 = price_element2.text\n",
    "\n",
    "                        sales_xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                        sales_element2 = driver.find_element(By.XPATH, sales_xpath2)\n",
    "                        sales_data2 = sales_element2.text\n",
    "\n",
    "                        # Create a new DataFrame with the extracted data\n",
    "                        new_data2 = pd.DataFrame({'ชื่อสินค้า': [data2], 'ราคา': [price_data2],'จำนวนขาย':[sales_data2],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                        # Concatenate the new DataFrame with the existing data_df\n",
    "                        data_df = pd.concat([data_df, new_data2], ignore_index=True)  \n",
    "                    except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                        continue  \n",
    "                df = df[df['Brand Name'] != store_name]\n",
    "                print(f'{store_name} มีสินค้า {store_item}')     \n",
    "            \n",
    "            \n",
    "                page_count = 0 \n",
    "                count = 0\n",
    "                try:\n",
    "                    for list_number in range(current_page, element_pagemax):\n",
    "                        url = f'https://shopee.co.th/{store_name}?page={str((list_number-1)+current_page)}'\n",
    "\n",
    "                        count += list_number\n",
    "                        \n",
    "                        if page_count == 20:\n",
    "                            \n",
    "                            current_link = pd.DataFrame({'Brand Name': [store_name], 'Brand Link':[url], 'Vm':[vm]})\n",
    "                            df = pd.concat([df, current_link]).reset_index(drop = True)\n",
    "                            break\n",
    "                        \n",
    "                        page_count += 1\n",
    "                        driver.get(url)\n",
    "                        time.sleep(5)\n",
    "                        \n",
    "                        for item in range(1, 31):  # Loop through items\n",
    "                            try:\n",
    "                                \n",
    "                                xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[1]/div/div'\n",
    "                                element = driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "                                # Extract and process data as needed\n",
    "                                data = element.text\n",
    "\n",
    "                                # Find the price element for the current item\n",
    "                                price_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                                price_element = driver.find_element(By.XPATH, price_xpath)\n",
    "\n",
    "                                # Extract and process price data\n",
    "                                price_data = price_element.text\n",
    "\n",
    "                                sales_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[1]/div[1]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                                sales_element = driver.find_element(By.XPATH, sales_xpath)\n",
    "                                sales_data = sales_element.text\n",
    "\n",
    "                                # Create a new DataFrame with the extracted data\n",
    "                                new_data = pd.DataFrame({'ชื่อสินค้า': [data], 'ราคา': [price_data],'จำนวนขาย':[sales_data],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                                # Concatenate the new DataFrame with the existing data_df\n",
    "                                data_df = pd.concat([data_df, new_data], ignore_index=True)\n",
    "                                \n",
    "\n",
    "                                store_item += 1\n",
    "    \n",
    "                            except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                                continue  \n",
    "                                \n",
    "                        for item in range(1, 31):  # Loop through items \n",
    "                            try:\n",
    "                            \n",
    "                                xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div'\n",
    "                                element2 = driver.find_element(By.XPATH, xpath2)\n",
    "\n",
    "                                # Extract and process data as needed\n",
    "                                data2 = element2.text\n",
    "\n",
    "                                # Find the price element for the current item\n",
    "                                price_xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                                price_element2 = driver.find_element(By.XPATH, price_xpath2)\n",
    "\n",
    "                                # Extract and process price data\n",
    "                                price_data2 = price_element2.text\n",
    "\n",
    "                                sales_xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                                sales_element2 = driver.find_element(By.XPATH, sales_xpath2)\n",
    "                                sales_data2 = sales_element2.text\n",
    "\n",
    "                                # Create a new DataFrame with the extracted data\n",
    "                                new_data2 = pd.DataFrame({'ชื่อสินค้า': [data2], 'ราคา': [price_data2],'จำนวนขาย':[sales_data2],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                                # Concatenate the new DataFrame with the existing data_df\n",
    "                                data_df = pd.concat([data_df, new_data2], ignore_index=True)  \n",
    "                                \n",
    "                                \n",
    "                            except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                                continue  \n",
    "                        print(f'{store_name} เก็บสินค้าครั้งใหม่ ได้จำนวน {store_item}')\n",
    "                except:\n",
    "                    print(\"Next page not found.\")\n",
    "            \n",
    "            # ลูปชั้น 1    \n",
    "            elif element_pagemax > 20:\n",
    "                page_count = 0\n",
    "        \n",
    "                try:\n",
    "                    \n",
    "                    for item in range(1, 31):  # Loop through items\n",
    "                            try:\n",
    "                                \n",
    "                                xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[1]/div/div'\n",
    "                                element = driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "                                # Extract and process data as needed\n",
    "                                data = element.text\n",
    "\n",
    "                                # Find the price element for the current item\n",
    "                                price_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                                price_element = driver.find_element(By.XPATH, price_xpath)\n",
    "\n",
    "                                # Extract and process price data\n",
    "                                price_data = price_element.text\n",
    "\n",
    "                                sales_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[1]/div[1]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                                sales_element = driver.find_element(By.XPATH, sales_xpath)\n",
    "                                sales_data = sales_element.text\n",
    "\n",
    "                                # Create a new DataFrame with the extracted data\n",
    "                                new_data = pd.DataFrame({'ชื่อสินค้า': [data], 'ราคา': [price_data],'จำนวนขาย':[sales_data],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                                # Concatenate the new DataFrame with the existing data_df\n",
    "                                data_df = pd.concat([data_df, new_data], ignore_index=True)\n",
    "\n",
    "                                store_item += 1\n",
    "                                \n",
    "                            except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                                continue\n",
    "                    page_count += 1\n",
    "                            \n",
    "                    for list_number in range(1, element_pagemax):\n",
    "                        url = f'https://shopee.co.th/{store_name}?page={str(list_number)}'\n",
    "                        \n",
    "                        page_count += 1\n",
    "                        \n",
    "                        if page_count == 20:\n",
    "                            current_link = pd.DataFrame({'Brand Name': [store_name], 'Brand Link':[url], 'Vm':[vm]})\n",
    "                            df = pd.concat([df, current_link]).reset_index(drop = True)\n",
    "                            break\n",
    "                        \n",
    "                        driver.get(url)\n",
    "                        time.sleep(5)\n",
    "                        \n",
    "                        for item in range(1, 31):  # Loop through items\n",
    "                            \n",
    "                            try:\n",
    "                                \n",
    "                                xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[1]/div/div'\n",
    "                                element = driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "                                # Extract and process data as needed\n",
    "                                data = element.text\n",
    "\n",
    "                                # Find the price element for the current item\n",
    "                                price_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                                price_element = driver.find_element(By.XPATH, price_xpath)\n",
    "\n",
    "                                # Extract and process price data\n",
    "                                price_data = price_element.text\n",
    "\n",
    "                                sales_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[1]/div[1]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                                sales_element = driver.find_element(By.XPATH, sales_xpath)\n",
    "                                sales_data = sales_element.text\n",
    "\n",
    "                                # Create a new DataFrame with the extracted data\n",
    "                                new_data = pd.DataFrame({'ชื่อสินค้า': [data], 'ราคา': [price_data],'จำนวนขาย':[sales_data],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                                # Concatenate the new DataFrame with the existing data_df\n",
    "                                data_df = pd.concat([data_df, new_data], ignore_index=True)\n",
    "\n",
    "                                store_item += 1\n",
    "                                \n",
    "                            except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                                continue\n",
    "                except:\n",
    "                    print(\"Next page not found.\")                    \n",
    "\n",
    "                print(f'{store_name} มีสินค้า {store_item}')    \n",
    "            # ลูปลบงานที่เสร็จแล้ว\n",
    "            elif element_pagemax == 1:\n",
    "                print(\"This store has only one page.\")\n",
    "                \n",
    "                for item in range(1, 31):  # Loop through items\n",
    "                    try:\n",
    "                        \n",
    "                        xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[1]/div/div'\n",
    "                        element = driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "                        # Extract and process data as needed\n",
    "                        data = element.text\n",
    "\n",
    "                        # Find the price element for the current item\n",
    "                        price_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div[1]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                        price_element = driver.find_element(By.XPATH, price_xpath)\n",
    "\n",
    "                        # Extract and process price data\n",
    "                        price_data = price_element.text\n",
    "\n",
    "                        sales_xpath = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[1]/div[1]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                        sales_element = driver.find_element(By.XPATH, sales_xpath)\n",
    "                        sales_data = sales_element.text\n",
    "\n",
    "                        # Create a new DataFrame with the extracted data\n",
    "                        new_data = pd.DataFrame({'ชื่อสินค้า': [data], 'ราคา': [price_data],'จำนวนขาย':[sales_data],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                        # Concatenate the new DataFrame with the existing data_df\n",
    "                        data_df = pd.concat([data_df, new_data], ignore_index=True)\n",
    "\n",
    "                        store_item += 1\n",
    "                    except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                        continue  \n",
    "                        \n",
    "                for item in range(1, 31):  # Loop through items\n",
    "                    try:\n",
    "                    \n",
    "                        xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div'\n",
    "                        element2 = driver.find_element(By.XPATH, xpath2)\n",
    "\n",
    "                        # Extract and process data as needed\n",
    "                        data2 = element2.text\n",
    "\n",
    "                        # Find the price element for the current item\n",
    "                        price_xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div/div[2]/div[2]/div/span[3]'\n",
    "                        price_element2 = driver.find_element(By.XPATH, price_xpath2)\n",
    "\n",
    "                        # Extract and process price data\n",
    "                        price_data2 = price_element2.text\n",
    "\n",
    "                        sales_xpath2 = f'//*[@id=\"main\"]/div/div[2]/div/div/div/div[2]/div/div[3]/div[2]/div[2]/div[2]/div/div[2]/div/div[{item}]/a/div/div/div[2]/div[3]/div[2]'\n",
    "                        sales_element2 = driver.find_element(By.XPATH, sales_xpath2)\n",
    "                        sales_data2 = sales_element2.text\n",
    "\n",
    "                        # Create a new DataFrame with the extracted data\n",
    "                        new_data2 = pd.DataFrame({'ชื่อสินค้า': [data2], 'ราคา': [price_data2],'จำนวนขาย':[sales_data2],'ชื่อร้านค้า': [store_name]})\n",
    "\n",
    "                        # Concatenate the new DataFrame with the existing data_df\n",
    "                        data_df = pd.concat([data_df, new_data2], ignore_index=True)  \n",
    "                    except (StaleElementReferenceException, TimeoutException, ConnectionRefusedError, NoSuchElementException ):\n",
    "                        continue  \n",
    "                    \n",
    "                #remove store name from df\n",
    "                df = df[df['Brand Name'] != store_name]\n",
    "                print(f'{store_name} มีสินค้า {store_item}')         \n",
    "            \n",
    "            else :\n",
    "                print(\"This store has no page.\")    \n",
    "\n",
    "                print(f'{store_name} มีสินค้า {store_item}')    \n",
    "            \n",
    "            # Reset the proxy index if it exceeds the number of proxies\n",
    "            if proxy_index == len(proxies) - 1:\n",
    "                proxy_index = 1\n",
    "                \n",
    "            # Move to the next proxy\n",
    "            proxy_index += 1\n",
    "            \n",
    "        # Reset the proxy index if it exceeds the number of proxies\n",
    "        if proxy_index == len(proxies) - 1:\n",
    "            proxy_index = 1\n",
    "            \n",
    "        # Move to the next proxy\n",
    "        proxy_index += 1\n",
    "            \n",
    "        driver.quit()\n",
    "        \n",
    "        \n",
    "\n",
    "        break\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Print the result or save to a file\n",
    "def convert_sales(s):\n",
    "    if 'พัน' in s:\n",
    "        return int(float(s.replace('ขายแล้ว ', '').replace(' ชิ้น', '').replace('พัน', '').strip()) * 1000)\n",
    "    elif s.strip() != '':\n",
    "        return int(s.replace('ขายแล้ว ', '').replace('ชิ้น', '').strip())\n",
    "    else:\n",
    "        return None  # หรือค่าอื่นที่คุณต้องการจะกำหนด\n",
    "\n",
    "# ใช้ apply เพื่อให้นำฟังก์ชันไปใช้กับทุกแถวของคอลัมน์ \"จำนวนขาย\"\n",
    "data_df['จำนวนขาย'] = data_df['จำนวนขาย'].apply(convert_sales)\n",
    "data_df['จำนวนขาย'] = data_df['จำนวนขาย'].fillna(0).astype(int)\n",
    "# data_df.to_csv('scraped_data.csv', index=False)\n",
    "\n",
    "\n",
    "data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ชื่อสินค้า</th>\n",
       "      <th>ราคา</th>\n",
       "      <th>จำนวนขาย</th>\n",
       "      <th>ชื่อร้านค้า</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acnoc Acneser Spot Gel 15 g...</td>\n",
       "      <td>249</td>\n",
       "      <td>ขายแล้ว 148 ชิ้น</td>\n",
       "      <td>acnoc_thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acnoc Acni Wash Cleanser 100 ml.</td>\n",
       "      <td>215</td>\n",
       "      <td>ขายแล้ว 77 ชิ้น</td>\n",
       "      <td>acnoc_thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acnoc Acneser Spot Gel 5 g. (แอคนอค แอคเนเซอร์...</td>\n",
       "      <td>110</td>\n",
       "      <td>ขายแล้ว 111 ชิ้น</td>\n",
       "      <td>acnoc_thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Lock Aqua Soothe SPF50 PA++++ 50 g.</td>\n",
       "      <td>870</td>\n",
       "      <td>ขายแล้ว 8 ชิ้น</td>\n",
       "      <td>acnoc_thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acnoc All Hybrid Essence 30 ml.</td>\n",
       "      <td>2,420</td>\n",
       "      <td>ขายแล้ว 9 ชิ้น</td>\n",
       "      <td>acnoc_thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>Carex Natural Antibacteria Hand Wash Fresh น้ำ...</td>\n",
       "      <td>311</td>\n",
       "      <td>ขายแล้ว 8 ชิ้น</td>\n",
       "      <td>cpconsumer_official</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>สินค้าหมด\\n-2%\\nImperial Leather Soap สบู่อิมพ...</td>\n",
       "      <td>147</td>\n",
       "      <td>ขายแล้ว 3.3พัน ชิ้น</td>\n",
       "      <td>cpconsumer_official</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>สินค้าหมด\\n-3%\\nC&amp;L น้ำปลาตราคนแบกกุ้ง ขนาด 70...</td>\n",
       "      <td>29</td>\n",
       "      <td>ขายแล้ว 298 ชิ้น</td>\n",
       "      <td>cpconsumer_official</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>สินค้าหมด\\n-3%\\nCarex Natural Antibacteria Han...</td>\n",
       "      <td>106</td>\n",
       "      <td>ขายแล้ว 47 ชิ้น</td>\n",
       "      <td>cpconsumer_official</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>สินค้าหมด\\n-5%\\nTCB ทีซีบีทูน่าก้อนในน้ำแร่ 18...</td>\n",
       "      <td>171</td>\n",
       "      <td>ขายแล้ว 89 ชิ้น</td>\n",
       "      <td>cpconsumer_official</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2211 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ชื่อสินค้า   ราคา  \\\n",
       "0                        Acnoc Acneser Spot Gel 15 g...    249   \n",
       "1                      Acnoc Acni Wash Cleanser 100 ml.    215   \n",
       "2     Acnoc Acneser Spot Gel 5 g. (แอคนอค แอคเนเซอร์...    110   \n",
       "3               Sun Lock Aqua Soothe SPF50 PA++++ 50 g.    870   \n",
       "4                       Acnoc All Hybrid Essence 30 ml.  2,420   \n",
       "...                                                 ...    ...   \n",
       "2206  Carex Natural Antibacteria Hand Wash Fresh น้ำ...    311   \n",
       "2207  สินค้าหมด\\n-2%\\nImperial Leather Soap สบู่อิมพ...    147   \n",
       "2208  สินค้าหมด\\n-3%\\nC&L น้ำปลาตราคนแบกกุ้ง ขนาด 70...     29   \n",
       "2209  สินค้าหมด\\n-3%\\nCarex Natural Antibacteria Han...    106   \n",
       "2210  สินค้าหมด\\n-5%\\nTCB ทีซีบีทูน่าก้อนในน้ำแร่ 18...    171   \n",
       "\n",
       "                 จำนวนขาย          ชื่อร้านค้า  \n",
       "0        ขายแล้ว 148 ชิ้น       acnoc_thailand  \n",
       "1         ขายแล้ว 77 ชิ้น       acnoc_thailand  \n",
       "2        ขายแล้ว 111 ชิ้น       acnoc_thailand  \n",
       "3          ขายแล้ว 8 ชิ้น       acnoc_thailand  \n",
       "4          ขายแล้ว 9 ชิ้น       acnoc_thailand  \n",
       "...                   ...                  ...  \n",
       "2206       ขายแล้ว 8 ชิ้น  cpconsumer_official  \n",
       "2207  ขายแล้ว 3.3พัน ชิ้น  cpconsumer_official  \n",
       "2208     ขายแล้ว 298 ชิ้น  cpconsumer_official  \n",
       "2209      ขายแล้ว 47 ชิ้น  cpconsumer_official  \n",
       "2210      ขายแล้ว 89 ชิ้น  cpconsumer_official  \n",
       "\n",
       "[2211 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df2 = data_df.copy()\n",
    "data_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NoPageLis = []\n",
    "len(NoPageLis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "x = 0\n",
    "while element_pagemax is None:\n",
    "    if element_pagemax is not None:\n",
    "        print('มีหน้า')\n",
    "        break\n",
    "    \n",
    "    elif s == 4:\n",
    "        element_pagemax = 0  \n",
    "        print('ไม่มีหน้า')\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        x = 1\n",
    "        print('มีหน้า111')\n",
    "    except:\n",
    "        print(\"Element not found.\")\n",
    "        \n",
    "    s =+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
